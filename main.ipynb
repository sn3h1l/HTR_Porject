{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "9mJiCW20EVKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tmaUlf9EQBE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "!wget -q https://git.io/J0fjL -O IAM_Words.zip\n",
        "!unzip -qq IAM_Words.zip\n",
        "!mkdir data\n",
        "!mkdir data/words\n",
        "!tar -xf IAM_Words/words.tgz -C data/words\n",
        "!mv IAM_Words/words.txt data\n",
        "\n",
        "data_dir = \"/content/data\"\n",
        "word_entries = []\n",
        "with open(f\"{data_dir}/words.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        if line[0] != \"#\" and line.split(\" \")[1] != \"err\":\n",
        "            word_entries.append(line.strip())\n",
        "\n",
        "np.random.shuffle(word_entries)\n",
        "\n",
        "split_index = int(0.8 * len(word_entries))\n",
        "train_entries = word_entries[:split_index]\n",
        "remaining_entries = word_entries[split_index:]\n",
        "val_index = int(0.5 * len(remaining_entries))\n",
        "val_entries = remaining_entries[:val_index]\n",
        "test_entries = remaining_entries[val_index:]\n",
        "\n",
        "assert len(word_entries) == len(train_entries) + len(val_entries) + len(test_entries)\n",
        "\n",
        "print(f\"Total Training Samples: {len(train_entries)}\")\n",
        "print(f\"Total Validation Samples: {len(val_entries)}\")\n",
        "print(f\"Total Test Samples: {len(test_entries)}\")\n",
        "\n",
        "image_base_path = os.path.join(data_dir, \"words\")\n",
        "\n",
        "def extract_image_paths_and_labels(samples):\n",
        "    img_paths, corrected_labels = [], []\n",
        "    for line in samples:\n",
        "        parts = line.split(\" \")\n",
        "        img_name = parts[0]\n",
        "        part1, part2 = img_name.split(\"-\")[:2]\n",
        "        img_path = os.path.join(image_base_path, part1, f\"{part1}-{part2}\", f\"{img_name}.png\")\n",
        "        if os.path.exists(img_path) and os.path.getsize(img_path) > 0:\n",
        "            img_paths.append(img_path)\n",
        "            corrected_labels.append(line)\n",
        "    return img_paths, corrected_labels\n",
        "\n",
        "train_img_paths, train_labels = extract_image_paths_and_labels(train_entries)\n",
        "val_img_paths, val_labels = extract_image_paths_and_labels(val_entries)\n",
        "test_img_paths, test_labels = extract_image_paths_and_labels(test_entries)\n",
        "\n",
        "unique_chars = set()\n",
        "max_label_len = 0\n",
        "cleaned_train_labels = []\n",
        "\n",
        "for label in train_labels:\n",
        "    word = label.split(\" \")[-1]\n",
        "    unique_chars.update(word)\n",
        "    max_label_len = max(max_label_len, len(word))\n",
        "    cleaned_train_labels.append(word)\n",
        "\n",
        "def clean_labels(labels):\n",
        "    return [label.split(\" \")[-1] for label in labels]\n",
        "\n",
        "cleaned_val_labels = clean_labels(val_labels)\n",
        "cleaned_test_labels = clean_labels(test_labels)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/characters\", \"rb\") as file:\n",
        "    char_mapping = pickle.load(file)\n",
        "\n",
        "char_to_num = StringLookup(vocabulary=char_mapping, mask_token=None)\n",
        "num_to_chars = StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "qyG2riMTEy3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_and_pad_image(image, img_size):\n",
        "    width, height = img_size\n",
        "    image = tf.image.resize(image, size=(height, width), preserve_aspect_ratio=True)\n",
        "    pad_height = height - tf.shape(image)[0]\n",
        "    pad_width = width - tf.shape(image)[1]\n",
        "\n",
        "    pad_height_top = pad_height // 2\n",
        "    pad_height_bottom = pad_height - pad_height_top\n",
        "    pad_width_left = pad_width // 2\n",
        "    pad_width_right = pad_width - pad_width_left\n",
        "\n",
        "    image = tf.pad(image, paddings=[[pad_height_top, pad_height_bottom], [pad_width_left, pad_width_right], [0, 0]])\n",
        "    image = tf.transpose(image, perm=[1, 0, 2])\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "img_width, img_height = 128, 32\n",
        "batch_size = 64\n",
        "padding_token = 99\n",
        "\n",
        "def preprocess_image(image_path, img_size=(img_width, img_height)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, 1)\n",
        "    image = resize_and_pad_image(image, img_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "def vectorize_label(label):\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "    label_length = tf.shape(label)[0]\n",
        "    padding = max_label_len - label_length\n",
        "    label = tf.pad(label, paddings=[[0, padding]], constant_values=padding_token)\n",
        "    return label\n",
        "\n",
        "def preprocess_images_and_labels(image_path, label):\n",
        "    image = preprocess_image(image_path)\n",
        "    label = vectorize_label(label)\n",
        "    return {\"image\": image, \"label\": label}\n",
        "\n",
        "def prepare_dataset(image_paths, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(preprocess_images_and_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset = prepare_dataset(train_img_paths, cleaned_train_labels)\n",
        "val_dataset = prepare_dataset(val_img_paths, cleaned_val_labels)\n",
        "test_dataset = prepare_dataset(test_img_paths, cleaned_test_labels)\n"
      ],
      "metadata": {
        "id": "q5dTPvmvEwO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "Yrzmt-rKGCdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_samples(dataset, save_path, num_samples=16):\n",
        "    for batch in dataset.take(1):\n",
        "        images, labels = batch[\"image\"], batch[\"label\"]\n",
        "        fig, ax = plt.subplots(4, 4, figsize=(15, 8))\n",
        "        for i in range(num_samples):\n",
        "            img = tf.image.flip_left_right(tf.transpose(images[i], perm=[1, 0, 2]))\n",
        "            img = (img * 255.0).numpy().astype(np.uint8)[:, :, 0]\n",
        "            label = labels[i]\n",
        "            decoded_label = tf.strings.reduce_join(num_to_chars(tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))))\n",
        "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
        "            ax[i // 4, i % 4].set_title(decoded_label.numpy().decode(\"utf-8\"))\n",
        "            ax[i // 4, i % 4].axis(\"off\")\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "visualize_samples(train_dataset, \"train_samples.png\")\n",
        "visualize_samples(test_dataset, \"test_samples.png\")\n"
      ],
      "metadata": {
        "id": "vWWb6y02F71M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Definition**"
      ],
      "metadata": {
        "id": "ARTimpfLGQda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_size = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\") * tf.ones(shape=(batch_size, 1), dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\") * tf.ones(shape=(batch_size, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        return y_pred\n",
        "def create_model():\n",
        "    input_img = keras.Input(shape=(img_width, img_height, 1), name=\"image\")\n",
        "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
        "\n",
        "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv1\")(input_img)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv2\")(x)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    new_shape = ((img_width // 4), (img_height // 4) * 64)\n",
        "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
        "    x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "    output = keras.layers.Dense(len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\")(x)\n",
        "    output = CustomCTCLayer(name=\"ctc_loss\")(labels, output)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\")\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    model.compile(optimizer=optimizer)\n",
        "    return model\n",
        "model = create_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "_bXdDptXGK1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "kgu2TCH1Gb1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stopping_cb]\n",
        ")\n",
        "\n",
        "def plot_training_history(history, save_path):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "plot_training_history(history, \"training_history.png\")\n"
      ],
      "metadata": {
        "id": "jqfC2t8yGUby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**"
      ],
      "metadata": {
        "id": "NBvG0ChfGmEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_objects = {\"CustomCTCLayer\": CustomCTCLayer}\n",
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/saved_pred_model.h5\", custom_objects=custom_objects)\n",
        "prediction_model = keras.models.Model(\n",
        "    inputs=reconstructed_model.get_layer(name=\"image\").input,\n",
        "    outputs=reconstructed_model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "\n",
        "pred_test_text = []\n",
        "\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :max_label_len]\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
        "        res = tf.strings.reduce_join(num_to_chars(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "\n",
        "for batch in test_dataset.take(3):\n",
        "    batch_images = batch[\"image\"]\n",
        "    print(batch_images.shape)\n",
        "    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    pred_test_text.append(pred_texts)\n",
        "    for i in range(16):\n",
        "        img = batch_images[i]\n",
        "        img = tf.image.flip_left_right(img)\n",
        "        img = tf.transpose(img, perm=[1, 0, 2])\n",
        "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
        "        img = img[:, :, 0]\n",
        "\n",
        "        title = f\"Prediction: {pred_texts[i]}\"\n",
        "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
        "        ax[i // 4, i % 4].set_title(title)\n",
        "        ax[i // 4, i % 4].axis(\"off\")\n",
        "    plt.savefig(\"Inference1.png\")\n",
        "flat_list = [item for sublist in pred_test_text for item in sublist]\n",
        "print(flat_list)\n",
        "sentence = ' '.join(flat_list)\n",
        "print(sentence)\n"
      ],
      "metadata": {
        "id": "fuDKAi5hGemg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4noIzwdxGoqo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}